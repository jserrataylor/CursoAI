{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Etapas del Desarrollo de un Modelo de Machine Learning**\n",
        "\n",
        "**1. Definición del Problema**\n",
        "Antes de empezar, es esencial definir claramente el problema que quieres resolver. ¿Es una clasificación, regresión, clustering, o alguna otra tarea?\n",
        "\n",
        "**2. Recopilación de Datos**\n",
        "Los datos son el núcleo de cualquier modelo de machine learning. Puedes obtener datos de diversas fuentes como bases de datos, archivos CSV, APIs, entre otros.\n",
        "\n",
        "**3. Preprocesamiento de Datos**\n",
        "Limpia y transforma tus datos:\n",
        "- Trata valores faltantes.\n",
        "- Convierte variables categóricas en numéricas.\n",
        "- Normaliza o estandariza los datos si es necesario.\n",
        "\n",
        "**4. División de Datos**\n",
        "Divide tus datos en conjuntos de entrenamiento y prueba. Esto te permite entrenar tu modelo con un subconjunto de datos y probarlo con otro para evaluar su rendimiento.\n",
        "\n",
        "**5. Elección del Modelo**\n",
        "Dependiendo de tu problema, elige un modelo adecuado (regresión lineal, árboles de decisión, redes neuronales, etc.)\n",
        "\n",
        "**6. Entrenamiento del Modelo**\n",
        "Usa el conjunto de entrenamiento para entrenar tu modelo. Esto implica alimentar al modelo con tus datos y ajustar sus parámetros.\n",
        "\n",
        "**7. Evaluación del Modelo**\n",
        "Una vez entrenado, evalúa el modelo con el conjunto de prueba. Utiliza métricas adecuadas (precisión, recall, MSE, etc.) para determinar el rendimiento del modelo.\n",
        "\n",
        "**8. Optimización**\n",
        "Si el rendimiento no es satisfactorio, considera:\n",
        "- Recopilar más datos.\n",
        "- Cambiar o ajustar el modelo.\n",
        "- Realizar ingeniería de características.\n",
        "\n",
        "**9. Despliegue (opcional)**\n",
        "Una vez satisfecho con el modelo, puedes desplegarlo en un servidor o en la nube para hacer predicciones en tiempo real.\n"
      ],
      "metadata": {
        "id": "UhRosPEMwBMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejemplo: Predicción del Precio de Casas en California**\n",
        "\n",
        "**1. Definición del Problema**\n",
        "Nuestro objetivo es predecir el precio mediano de las casas en California basándonos en características como la ubicación, el tamaño, la edad del inmueble y más. Se trata de un problema de regresión.\n",
        "\n",
        "**2. Recopilación de Datos**\n",
        "Vamos a utilizar el dataset \"California Housing\" que ya viene incluido en Scikit-learn, una biblioteca de Python para machine learning.\n",
        "\n",
        "**3. Preprocesamiento de Datos**\n",
        "- Comprobamos valores faltantes y decidimos cómo manejarlos (eliminarlos o imputarlos).\n",
        "- Convertimos variables categóricas (si las hay) en numéricas usando técnicas como el one-hot encoding.\n",
        "- Estandarizamos las características para que tengan una escala similar.\n",
        "\n",
        "**4. División de Datos**\n",
        "Dividimos el dataset en un conjunto de entrenamiento (80% de los datos) y un conjunto de prueba (20% de los datos).\n",
        "\n",
        "**5. Elección del Modelo**\n",
        "Dado que es un problema de regresión, comenzamos con un modelo de regresión lineal como punto de partida.\n",
        "\n",
        "**6. Entrenamiento del Modelo**\n",
        "Entrenamos el modelo de regresión lineal usando el conjunto de entrenamiento.\n",
        "\n",
        "**7. Evaluación del Modelo**\n",
        "Evaluamos el modelo en el conjunto de prueba utilizando el error cuadrático medio (MSE) como métrica.\n",
        "\n",
        "**8. Optimización**\n",
        "Si el MSE es alto, consideramos:\n",
        "- Añadir más características.\n",
        "- Probar modelos más complejos como regresión polinómica o árboles de decisión.\n",
        "- Revisar los datos para asegurarnos de que estén limpios y sean relevantes.\n",
        "\n",
        "**9. Despliegue**\n",
        "Una vez que estemos satisfechos con el rendimiento del modelo, podemos desplegarlo en un servidor o en una aplicación web para que otros usuarios puedan ingresar características de una casa y obtener una predicción del precio."
      ],
      "metadata": {
        "id": "Ax_81sKY9kj7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Script de Implementación Básica"
      ],
      "metadata": {
        "id": "KWLcs06c-Dy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Requerimientos de instalación\n",
        "pip install numpy scikit-learn pandas"
      ],
      "metadata": {
        "id": "4OXnB0od9qHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Problemas de clasificación**\n",
        "Uno de los **problemas de clasificación** más comunes y conocidos es el conjunto de datos de Iris. El dataset de Iris contiene mediciones de 150 flores de iris de tres diferentes especies: Setosa, Versicolour y Virginica. Las características medidas incluyen la longitud y el ancho del sépalo y del pétalo de cada flor.\n",
        "\n",
        "El objetivo es construir un modelo que pueda predecir la especie de una flor en función de estas cuatro características.\n",
        "\n",
        "A continuación, ejemplo simple utilizando el conjunto de datos de Iris y un modelo de clasificación llamado árbol de decisión utilizando Python y la biblioteca Scikit-learn:"
      ],
      "metadata": {
        "id": "zA1VviSH5zwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar las bibliotecas necesarias\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Cargar el conjunto de datos de Iris\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Dividir los datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Crear y entrenar el modelo de árbol de decisión\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predecir con el conjunto de prueba\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluar el rendimiento del modelo\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwbRKG4b50NO",
        "outputId": "376076ba-afac-49f1-add0-1390a18ce4f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9555555555555556\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        16\n",
            "           1       0.91      0.91      0.91        11\n",
            "           2       0.94      0.94      0.94        18\n",
            "\n",
            "    accuracy                           0.96        45\n",
            "   macro avg       0.95      0.95      0.95        45\n",
            "weighted avg       0.96      0.96      0.96        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicción de precios en casas"
      ],
      "metadata": {
        "id": "FjndSGYM8YGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando bibliotecas necesarias\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 2. Recopilación de Datos\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# 3. Preprocesamiento de Datos\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# 4. División de Datos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. y 6. Elección y Entrenamiento del Modelo\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 7. Evaluación del Modelo\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Error Cuadrático Medio: {mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffsz1Pzc9vzZ",
        "outputId": "a55f8906-759e-48df-c9d6-ea6efdd8793f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error Cuadrático Medio: 0.555891598695244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1WGiXBY5Nnf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El **Error Cuadrático Medio** (ECM o MSE, por sus siglas en inglés \"**Mean Squared Error**\") es una métrica que *se utiliza para evaluar la precisión de un modelo de regresión*. Esencialmente, mide cuán cerca están las predicciones del modelo a los valores reales. Es una de las métricas más utilizadas para problemas de regresión.\n",
        "\n",
        "La fórmula para calcular el MSE es:\n",
        "\n",
        "\\[\n",
        "MSE = $\\frac{1}{n} \\sum_{i=1}^{n} (y_{i} - \\hat{y}_{i})^{2}\n",
        "$\\]\n",
        "\n",
        "Donde:\n",
        "- $( n $\\) es el número total de observaciones (o puntos de datos).\n",
        "- $( y_{i} $\\) es el valor real de la observación $( i $\\).\n",
        "- $( \\hat{y}_{i} $\\) es el valor predicho por el modelo para la observación $( i $\\).\n",
        "\n",
        "En términos simples, para cada punto de datos, se calcula la diferencia entre el valor real y el valor predicho, se eleva al cuadrado, y luego se toma el promedio de todas estas diferencias al cuadrado para obtener el MSE.\n",
        "\n",
        "El **Error Cuadrático Medio**: 0.555891598695244\", significa que, en promedio, el cuadrado de la diferencia entre los valores reales y las predicciones del modelo es de aproximadamente 0.556.\n",
        "\n",
        "En general:\n",
        "- Un **MSE de 0** indica que el modelo predice perfectamente sin errores (lo cual es raro y podría indicar un sobreajuste).\n",
        "- Un **MSE mayor que 0** indica algún grado de error en las predicciones del modelo. Cuanto mayor sea el MSE, mayor será el error y viceversa. Es útil comparar el MSE de diferentes modelos para determinar cuál tiene un mejor rendimiento, pero también es importante tener en cuenta otras métricas y el contexto del problema."
      ],
      "metadata": {
        "id": "9XTJBihR_REO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install joblib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ewQWXV-Xd4P",
        "outputId": "ded3987e-a212-4b7c-eb33-8c99d37eb0b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Creación de datos dummy\n",
        "data = {\n",
        "    'review_text': [\"Me encantó\", \"Fue una perdida de tiempo\", \"Fantastica\", \"Terrible y aburrida\", \"Encantadora y exitante\", \"poco interesante\"],\n",
        "    'is_positive': [1, 0, 1, 0, 1, 0]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Pipeline: Pre-procesamiento y Modelo\n",
        "model_pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', MultinomialNB())\n",
        "])\n",
        "\n",
        "# División de datos y entrenamiento del modelo\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['review_text'], df['is_positive'], test_size=0.5, random_state=42)\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluación del modelo\n",
        "predictions = model_pipeline.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions)\n",
        "recall = recall_score(y_test, predictions)\n",
        "f1 = f1_score(y_test, predictions)\n",
        "\n",
        "# Resultados\n",
        "print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1: {f1:.2f}\")\n",
        "\n",
        "# Guardar el modelo\n",
        "model_filename = 'movie_review_classifier.pkl'\n",
        "joblib.dump(model_pipeline, model_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBW0n67SXoVu",
        "outputId": "ba8807c8-7797-4781-c4d2-dc1c49fd35cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.33, Precision: 0.33, Recall: 1.00, F1: 0.50\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['movie_review_classifier.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "def load_model(model_path):\n",
        "    \"\"\"\n",
        "    Carga un modelo de clasificación previamente entrenado.\n",
        "\n",
        "    :param model_path: str, ruta al modelo guardado.\n",
        "    :return: modelo cargado.\n",
        "    \"\"\"\n",
        "    return joblib.load(model_path)\n",
        "\n",
        "def predict_review(model, review_text):\n",
        "    \"\"\"\n",
        "    Usa el modelo cargado para predecir si una revisión de película es positiva o no.\n",
        "\n",
        "    :param model: modelo de clasificación cargado.\n",
        "    :param review_text: str, texto de la revisión a predecir.\n",
        "    :return: predicción (1: positiva, 0: negativa).\n",
        "    \"\"\"\n",
        "    return model.predict([review_text])[0]\n",
        "\n",
        "# Ruta al modelo guardado\n",
        "model_path = 'movie_review_classifier.pkl'\n",
        "\n",
        "# Cargar el modelo\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Solicitar texto de revisión al usuario\n",
        "review_text = input(\"Please enter the movie review: \")\n",
        "\n",
        "# Predicción\n",
        "is_positive = predict_review(model, review_text)\n",
        "\n",
        "# Resultado\n",
        "if is_positive:\n",
        "    print(\"The review is predicted to be positive.\")\n",
        "else:\n",
        "    print(\"The review is predicted to be negative.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XydMWKdtXtG6",
        "outputId": "fcc7520c-e0c9-4242-90d7-95dc870f4e10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the movie review: Aburrida\n",
            "The review is predicted to be positive.\n"
          ]
        }
      ]
    }
  ]
}