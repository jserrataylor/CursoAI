{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOg6mjLRNy0cK5UC49EBvEP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jserrataylor/cursoAI/blob/main/Neurona_Simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron"
      ],
      "metadata": {
        "id": "SzUeQVCX7qW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El perceptrón es un tipo de red neuronal artificial y uno de los algoritmos más simples para el aprendizaje supervisado de clasificadores binarios. Un clasificador binario es una función que puede decidir si una entrada, representada por un vector de números, pertenece a una clase específica o no. El perceptrón fue inventado en 1957 por Frank Rosenblatt.\n",
        "\n",
        "\n",
        "El perceptrón es un modelo fundamental en el aprendizaje de máquinas y un pionero en el estudio de redes neuronales, siendo crucial para entender conceptos más avanzados en inteligencia artificial.\n",
        "\n",
        "![Grafica](https://www.alexisalulema.com/wp-content/uploads/2022/09/image-2-1536x808.png)\n",
        "\n",
        "Esta imagen muestra una representación esquemática de un perceptrón simple, que es la forma más básica de una red neuronal artificial. Aquí está lo que representa cada parte del esquema:\n",
        "\n",
        "- **Nodos de entrada (x1, x2, x3, ..., xm)**: Estos círculos amarillos representan las neuronas de entrada, que reciben las señales a procesar. En este caso, hay m entradas, lo que sugiere que el perceptrón puede procesar m características diferentes.\n",
        "\n",
        "- **Pesos (w1, w2, w3, ..., wm)**: Los círculos color salmón a la derecha de las entradas representan los pesos asignados a cada señal de entrada. Estos pesos son los factores que se ajustan durante el proceso de aprendizaje de la red neuronal y determinan la importancia de cada entrada en la salida del perceptrón.\n",
        "\n",
        "- **Sumatoria (Σ)**: El círculo grande azul en el centro es el sumador. Su función es multiplicar cada entrada (xi) por su peso correspondiente (wi) y sumar todos estos productos. Esto se conoce como la suma ponderada de las entradas.\n",
        "\n",
        "- **Función de activación**: El cuadro rojo en el extremo derecho representa la función de activación que se aplica a la suma ponderada de las entradas. La línea negra dentro del cuadro rojo es un gráfico de una función escalón, que es una función de activación común en los perceptrones. Esta función convierte la suma ponderada en una salida binaria, generalmente 0 o 1, que se utiliza para la clasificación.\n",
        "\n",
        "\n",
        "## Características del Perceptrón:\n",
        "\n",
        "1. **Estructura Básica**:\n",
        "   - **Entradas**: Recibe múltiples señales de entrada (por ejemplo, características de un conjunto de datos).\n",
        "   - **Pesos**: Cada entrada está asociada con un peso que representa su importancia. Estos pesos se ajustan durante el proceso de entrenamiento.\n",
        "   - **Suma Ponderada**: Calcula una suma ponderada de sus entradas, donde la suma ponderada es el producto escalar de las entradas con sus respectivos pesos.\n",
        "   - **Función de Activación**: La suma ponderada se pasa a través de una función de activación, generalmente una función escalón (umbral). Esto produce una salida binaria (por ejemplo, 0 o 1).\n",
        "\n",
        "2. **Proceso de Aprendizaje**:\n",
        "   - El perceptrón se entrena sobre un conjunto de ejemplos de entrenamiento.\n",
        "   - Ajusta los pesos basándose en el error de las salidas predichas comparadas con las salidas deseadas.\n",
        "   - El ajuste se realiza típicamente usando la regla de aprendizaje del perceptrón, que es una forma de aprendizaje supervisado.\n",
        "\n",
        "3. **Limitaciones**:\n",
        "   - El perceptrón solo puede clasificar conjuntos de datos linealmente separables. Esto significa que solo puede crear un límite de decisión lineal entre las diferentes clases.\n",
        "   - No puede resolver problemas no lineales, como la operación XOR.\n",
        "\n",
        "4. **Evolución y Uso**:\n",
        "   - A pesar de su simplicidad, el perceptrón sentó las bases para redes neuronales más complejas.\n",
        "   - A menudo se utiliza como un bloque de construcción para redes neuronales más grandes y complejas.\n"
      ],
      "metadata": {
        "id": "K0ecZAwX7vd6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcXoUJ8gg_I8",
        "outputId": "53e8f29a-45fb-40f0-ddd7-02ecc72bbea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 1:\n",
            "Entrada: [0, 0] -> Pesos: [0.5, 1.0, 1.0] -> Error: -1\n",
            "Entrada: [1, 0] -> Pesos: [0.0, 0.5, 1.0] -> Error: -1\n",
            "Entrada: [0, 1] -> Pesos: [-0.5, 0.5, 0.5] -> Error: -1\n",
            "Entrada: [1, 1] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "------\n",
            "Época 2:\n",
            "Entrada: [0, 0] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "Entrada: [1, 0] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "Entrada: [0, 1] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "Entrada: [1, 1] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "------\n",
            "Época 3:\n",
            "Entrada: [0, 0] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "Entrada: [1, 0] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "Entrada: [0, 1] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "Entrada: [1, 1] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "------\n",
            "Época 4:\n",
            "Entrada: [0, 0] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "Entrada: [1, 0] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "Entrada: [0, 1] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "Entrada: [1, 1] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "------\n",
            "Época 5:\n",
            "Entrada: [0, 0] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "Entrada: [1, 0] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "Entrada: [0, 1] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "Entrada: [1, 1] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "------\n",
            "Época 6:\n",
            "Entrada: [0, 0] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "Entrada: [1, 0] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "Entrada: [0, 1] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "Entrada: [1, 1] -> Pesos: [-0.5, 0.5, 0.5] -> Error: 0\n",
            "------\n"
          ]
        }
      ],
      "source": [
        "class SimpleNeuron:\n",
        "\n",
        "    def __init__(self, learning_rate, initial_weights):\n",
        "        \"\"\"\n",
        "        Inicializa la neurona con una tasa de aprendizaje y pesos iniciales.\n",
        "        \"\"\"\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = initial_weights\n",
        "\n",
        "    def activate(self, weighted_sum):\n",
        "        \"\"\"\n",
        "        Función de activación: devuelve 1 si la suma ponderada es positiva y 0 en caso contrario.\n",
        "        \"\"\"\n",
        "        return 1 if weighted_sum > 0 else 0\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        \"\"\"\n",
        "        Realiza una predicción basada en las entradas y los pesos actuales.\n",
        "        \"\"\"\n",
        "        weighted_sum = sum([i*w for i, w in zip(inputs, self.weights)])\n",
        "        return self.activate(weighted_sum)\n",
        "\n",
        "    def train(self, inputs, desired_output):\n",
        "        \"\"\"\n",
        "        Entrena la neurona ajustando los pesos basados en el error entre la salida deseada y la predicción.\n",
        "        \"\"\"\n",
        "        prediction = self.predict(inputs)\n",
        "        error = desired_output - prediction\n",
        "        self.weights = [w + self.learning_rate * error * i for w, i in zip(self.weights, inputs)]\n",
        "        return error, self.weights\n",
        "\n",
        "# Datos iniciales\n",
        "initial_weights = [1.0, 1.0, 1.0]\n",
        "learning_rate = 0.5\n",
        "inputs_outputs = [\n",
        "    ([1, 0, 0], 0),\n",
        "    ([1, 1, 0], 0),\n",
        "    ([1, 0, 1], 0),\n",
        "    ([1, 1, 1], 1)\n",
        "]\n",
        "\n",
        "# Crear una neurona\n",
        "neuron = SimpleNeuron(learning_rate, initial_weights)\n",
        "\n",
        "# Simular la evolución de la neurona durante varias épocas\n",
        "epochs = 6\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Época {epoch + 1}:\")\n",
        "    for inputs, desired_output in inputs_outputs:\n",
        "        error, new_weights = neuron.train(inputs, desired_output)\n",
        "        print(f\"Entrada: {inputs[1:]} -> Pesos: {new_weights} -> Error: {error}\")\n",
        "    print(\"------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definir la tasa de aprendizaje\n",
        "learning_rate = 0.5\n",
        "\n",
        "# Inicializar los pesos, por ejemplo, a 1\n",
        "weights = np.array([1.0, 1.0, 1.0])  # W0 es el sesgo, W1 y W2 son los pesos\n",
        "\n",
        "# Definir la función de activación, usaremos una función escalón\n",
        "def activation_function(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "# Función para el entrenamiento del perceptrón\n",
        "def train_perceptron(inputs, targets, epochs):\n",
        "    global weights\n",
        "    for epoch in range(epochs):\n",
        "        epoch_errors = []\n",
        "        for input, target in zip(inputs, targets):\n",
        "            # Calcula la suma ponderada\n",
        "            weighted_sum = np.dot(input, weights[1:]) + weights[0]  # W0 es el sesgo\n",
        "            # Calcula la salida de la función de activación\n",
        "            output = activation_function(weighted_sum)\n",
        "            # Calcula el error\n",
        "            error = target - output\n",
        "            epoch_errors.append(error)\n",
        "            # Actualiza los pesos y el sesgo\n",
        "            weights[1:] += learning_rate * error * input\n",
        "            weights[0] += learning_rate * error\n",
        "        # Imprimir la información de la época\n",
        "        epoch_accuracy = (np.array(epoch_errors) == 0).mean()\n",
        "        print(f'Época {epoch+1} - Error: {np.sum(np.abs(epoch_errors))}, Precisión: {epoch_accuracy}')\n",
        "        # Almacenar métricas de la época\n",
        "        epoch_metrics.append((epoch+1, np.sum(np.abs(epoch_errors)), epoch_accuracy))\n",
        "\n",
        "    return epoch_metrics\n",
        "\n",
        "# Datos de entrenamiento\n",
        "inputs = np.array([\n",
        "    # X1, X2\n",
        "    [0, 0],\n",
        "    [1, 0],\n",
        "    [0, 1],\n",
        "    [1, 1],\n",
        "])\n",
        "\n",
        "# Etiquetas objetivo (Lo que queremos [1])\n",
        "targets = np.array([0, 0, 0, 1])\n",
        "\n",
        "# Lista para almacenar las métricas de cada época\n",
        "epoch_metrics = []\n",
        "\n",
        "# Entrenar el perceptrón\n",
        "metrics = train_perceptron(inputs, targets, epochs=6)\n",
        "\n",
        "# Imprimir los pesos finales y las métricas de cada época\n",
        "weights, metrics\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtJiuaMAVzbo",
        "outputId": "00cd252f-e2a4-4180-cd6e-0acf188b9908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 1 - Error: 3, Precisión: 0.25\n",
            "Época 2 - Error: 2, Precisión: 0.5\n",
            "Época 3 - Error: 3, Precisión: 0.25\n",
            "Época 4 - Error: 2, Precisión: 0.5\n",
            "Época 5 - Error: 1, Precisión: 0.75\n",
            "Época 6 - Error: 0, Precisión: 1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-1.5,  0.5,  1. ]),\n",
              " [(1, 3, 0.25),\n",
              "  (2, 2, 0.5),\n",
              "  (3, 3, 0.25),\n",
              "  (4, 2, 0.5),\n",
              "  (5, 1, 0.75),\n",
              "  (6, 0, 1.0)])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}